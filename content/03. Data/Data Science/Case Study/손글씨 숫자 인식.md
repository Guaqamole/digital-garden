---
title: 손글씨 숫자 인식
date: 2024-05-02
draft: false
tags:
  - CaseStudy
problem-type: Deep Learning
dataset: https://www.tensorflow.org/datasets/catalog/mnist?hl=ko
topic: Classification
---
## About MNIST
![|525](https://i.imgur.com/EBTTiGD.png)

- 0 부터 9까지 숫자 이미지로 구성되어있다.
- 훈련 이미지가 6만장
- 시험 이미지가 1만장
- 일반적으로는 훈련 이지미들을 사용하여 모델을 학습하고
- 학습한 모델로 시험 이미지를 얼마나 정확하게 분류하는지 평가한다.

### Spec
- 각 이미지 데이터는 28 x 28 크기의 회색조 이미지
- 각 픽셀은 0에서 255까지의 값을 취한다.
- 이미지에서는 또한 7, 2, 1 과 같이 그 이미지가 실제 의미하는 숫자가 레이블로 붙어있다.

## Beginner (학습 없이 추론만)
- 이미 학습된 매개변수를 사용하여 학습 과정은 생략하고, 추론 과정만 구현
- 추론 과정은 신경망의 순전파 (forward propagation) 라고한다.


### 접근 방식
1. MNIST 데이터셋을 내려받아 이미지를 넘파이로 배열로 변환 (mnist.py)
```python
import sys, os
sys.path.append(os.pardir)

from dlscratch.dataset.mnist import load_mnist

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)
# 각 데이터의 형상 출력 
print(x_train.shape) # (60000, 784) 
print(t_train.shape) # (60000, )
print(x_test.shape) # (10000, 784) 
print(t_test.shape) # (10000,)
```

#### load_mnist()
load mnist 함수는 읽은MNIST데이터를"(훈련이미지, 훈련레이블), (시험이미지, 시험레이 블)" 형식으로반환합니다. 
- normalize: 입력이미지의픽셀 값을0.0~ 1.0 사이의값으로정규화. False로설정하면입력이미지의픽셀
은원래값 그대로0~255 사이의값을유지
- flatten: 입력이미지를 평탄하게, 즉1차원배열로만들지를정합니다.   False로설정하면입력이미지를1×28 X28 의3차원배열로, True로설정하면784개의원소로이뤄진1차원배열로저장

2. MNIST 이미지 화면으로 불러와보기
```python
from PIL import Image

def img_show(img, title):
    pil_img = Image.fromarray(np.uint8(img))
    pil_img.show(title=title)

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)

img = x_train[0]
label = t_train[0]
print(label) # 5

print(img.shape)
reshape_img = img.reshape(28,28)
print(reshape_img.shape)

img_show(img, "img") # img = (784,)
img_show(reshape_img, "reshape_img") # reshape_img = (28, 28)
```

3. 추론 처리 (학습은 스킵)
MNIST 데이터셋을가지고추론을수행하는신경망을구현할차례입니다. 이신경망은:
- 입력층 뉴런을784개
	- 뉴런이784개인이유는 이미지크기가28x28=784이기때문
- 출력층 뉴런을 10개로 구성 합니다. 
	- 뉴런이10개인이유는이문제가0에서9까지의숫자를구분하는문제이기때문

한편, 은닉층은총두개로, 첫번째은닉층에는50개의뉴런을, 두번째은닉층에는100개의뉴런을배치할것입니다. 
여기서50과100은 임의로정한값입니다.

#### get_data , init_network, predict
```python
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def softmax(a):
	c = np.max(a)
	exp_a = np.exp(a - c) # overflow 대비
	sum_exp_a = np.sum(exp_a)
	y = exp_a / sum_exp_a
	return y

def get_data():
    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)
    return x_test, t_test

def init_network():
    with open("sample_weight.pkl", 'rb') as f:
        network = pickle.load(f)
    return network

def predict(network, x):
    W1, W2, W3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']
    a1 = np.dot(x, W1) + b1 
    z1 = sigmoid(a1)
    
    a2 = np. dot(z1, W2) + b2 
    z2 = sigmoid(a2)
    
    a3 = np.dot(22, W3) + b3 
    y = softmax(a3)
    
    return y
```

#### 실행
```python
trains, labels = get_data()
network = init_network()

accuracy_cnt = 0
for i in range(len(trains)):
    y = predict(network, trains[i])
    p = np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다. -> 예측 결과.
    if p == labels[i]: # 예측 결과와 정답(레이블)을 비교
        accuracy_cnt += 1
print("Accuracy:" + str(float(accuracy_cnt) / len(trains)))
>> Accuracy:0.9352
```

#### 1개 이미지만 계산해보기
![|650](https://i.imgur.com/ueU2SiI.png)
```python
x, _ = get_data()
network = init_network()
W1, W2, W3 = network['W1'], network['W2'], network['W3']

x.shape    #(10000, 784)
x[0].shape #(784,)
W1.shape   #(784, 50)
W2.shape   #(50, 100)
W3.shape   #(100, 10)
```

#### 배치 처리
![|575](https://i.imgur.com/NWDS4V1.png)
하나로묶은입력데이터를배치라합니다. 배치가곧묶음이란의미죠. 이미지가지 폐처럼다발로묶여있다고생각하면됩니다
```python
x, t = get_data()
network = init_network()
batch_size = 100
accuracy_cnt = 0

for i in range(0, len(x), batch_size):
    x_batch = x[i:i+batch_size]
    y_batch = predict(network, x_batch)
    p = np.argmax(y_batch, axis=1)
    accuracy_cnt += np.sum(p == t[i:i + batch_size])
print("Accuracy:" + str(float(accuracy_cnt) / len(x)))
```

## Beginner 2 (학습 + 추론)
신경망의특징은데이터를보고학습할수있다는점입니다. 

데이터에서학습한다는것은 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다는뜻이죠.

만약 든매개변수를수작업으로결정해야한다고상상해보세요. 생각만해도끔찍합니다. 

이를테면 2장의퍼셉트론예에서는 진리표를 보면서사람이 수작업으로 매개 변수값을 설정했죠. 
하지만 이때는매개변수가겨우3개였습니다. 
실제신경망에서는 수천에서수만입니다. 나아가층을깊게한딥러닝정도되면그수는수억에이 를수도있습니다

> [!info] 데이터 주도 학습
> 기계학습은 데이터가 생명입니다. 데이터에서답을찾고데이터에서패턴을발견하고데이터 로이야기를만드는, 그것이바로기계학습이죠.
> 기계 학습에서는 사람의 개입을 최소화하고 수집한 데이터로부터 패턴을 찾으려 시도합니다. 게다가 신경망과 딥러닝은 기존 기계학습에서 사용하던방법보다 사람의 개입을 더욱 배제할 수 있게 해주는 중요한 특성을 지녔습니다.


![|800](https://i.imgur.com/xmNtSdt.png)
