---
title: Elasticsearch
date: 2024-04-12
draft: false
tags:
  - Elastic
complete: true
---
## Architecture Overview
Elasticsearch 는 Apache Lucene 을 코어 라이브러리로 사용하고 있다. Lucene은 문서를 색인하고 검색하는 라이브러리이다. 
![|700](https://i.imgur.com/Q5cZcWx.png)

### Cluster & Nodes
클러스터는 도큐먼트를 여러 노드에 분산시켜 저장할 수 있고, 모든 노드는 클러스터의 인덱싱 및 도큐먼트 검색 기능에 참여한다. 노드의 타입에 따라 수행하는 역할이 다르며, 하나의 노드에 복수의 타입을 할당할 수 있다.
![|675](https://i.imgur.com/Dq2DaDg.png)

노드와 외부 클라이언트 간 통신은 Application 계층(L7)에서 HTTP 프로토콜(http 포트 : 9200~9299)로 동작하고, 클러스터 내부에 있는 노드 간의 통신은 Transport 계층(L4)에서 TCP 프로토콜(tcp 포트 : 9300~9399)로 동작한다. 

외부 클라이언트가 REST API를 사용하여 클러스터에 요청을 전송하면 특정 타입의 노드는 해당 요청을 수신하고, 필요한 경우 Transport 계층을 사용하여 다른 노드로 추가 작업을 요청한다. 기본적으로 모든 노드는 외부 클라이언트의 HTTP 요청을 처리할 수 있지만, 클라이언트의 HTTP 요청을 처리하는 역할은 특정 타입의 노드만 수행하도록 제한된다.

### Types of Nodes

| **종류**   | **역할**                                |
| -------- | ------------------------------------- |
| 마스터 노드   | 클러스터 상태 관리 및 메타데이터 관리                 |
| 데이터 노드   | 문서 색인 및 검색 요청 처리                      |
| 코디네이팅 노드 | 요청을 데이터 노드로 전달하고, 다시 데이터 노드로부터 결과를 취합 |
| 인제스트 노드  | 색인되는 문서의 데이터 전처리                      |

#### 마스터(Master) 노드
- 클러스터는 반드시 하나의 마스터 노드를 가져야 한다.
- 마스터 노드는 클러스터의 상태를 모니터링하고, 노드에 샤드를 할당하는 등의 역할을 담당한다. 클러스터 상태 정보는 클러스터 설정, 인덱스 설정(매핑 정보, 물리적 위치 등), 노드 상태 등을 포함한다.
	- Ex. 마스터 노드는 ping 요청을 수행하여 노드의 상태를 확인할 수 있다.

#### 데이터(Data) 노드
- 데이터 노드는 모든 데이터 관련 작업(인덱싱, 검색, 집계)을 담당한다.
- 실질적인 데이터 처리를 담당하기 때문에 일반적으로 가장 부하를 많이 받게 된다.
    - 다른 타입의 노드보다 더 많은 리소스(CPU, Memory, Disk)를 사용한다.
    - 모니터링을 통해 데이터 노드의 부하 상태를 체크하는 것이 중요하다.
    - 특정 노드에 부하가 집중된다면, 해당 노드의 샤드를 다른 데이터 노드로 재배치하여 부하를 분산시킬 수 있다.
- 클러스터를 구성할 때, 마스터 노드와 데이터 노드를 전용 노드로 구성하는 것이 좋다.
    - 단일 노드가 데이터 노드와 마스터 노드의 역할을 같이 수행하는 경우, 데이터 노드의 부하가 마스터 노드의 성능에 영향을 미칠 수 있다.
    - 마스터 노드의 성능 저하는 클러스터 전체의 안정성을 해칠 수 있으므로, 가능하면 마스터 노드와 데이터 노드를 전용 노드로 구성하는 것이 좋다.

#### 인제스트(Ingest) 노드
![](https://i.imgur.com/41OQg3a.png)

- 인제스트 노드는 인제스트 파이프라인을 실행하는 역할을 담당한다.
    - 인제스트 파이프라인은 도큐먼트를 인덱싱하기 전에 도큐먼트를 전처리하는 역할을 담당한다.

#### 코디네이터(Coordinator) 노드
![](https://i.imgur.com/0m04GYW.png)
- 코디네이터 노드는 외부 클라이언트의 HTTP 요청을 처리하는 역할을 수행한다.
    - Elasticsearch에서 로드밸런서와 비슷한 역할을 수행하며, 요청을 데이터 노드에 위임하고, 결과를 수집하여 하나의 최종 결과로 집계하여 클라이언트에 응답한다.
    - 코디네이터 노드가 데이터 쿼리를 요청 받은 경우 다음과 같은 순서로 해당 요청을 처리한다.
        - 1. 외부 클라이언트로부터 쿼리를 요청 받는다.
        - 2. 클러스터의 모든 노드에게 동일한 쿼리를 요청한다. (클라이언트의 요청에 _routing 값이 포함된 경우, _routing을 통해 어떤 노드의 어떤 샤드가 해당 데이터를 갖고 있는지 알 수 있으므로, 해당 노드에게만 쿼리를 요청)
        - 3. 상기 2번에서 요청한 노드로부터 결과 데이터를 받아 집계한다.
        - 4. 집계 결과를 클라이언트로 보낸다.
- 클러스터 전체의 상태와 노드들의 부하 상태를 고려하여 적절한 노드에 요청을 전달한다.
- 검색이나 집계 요청이 많은 경우, 병목 현상을 방지하기 위해 두 개의 코디네이터 전용 노드를 사용하는 것이 좋다.
- 데이터를 집계할 때 CPU와 메모리를 많이 사용하기 때문에, 가능한 코어 수가 많은 CPU를 사용하는 것이 좋다.

### Shards
Elasticsearch가 확장성이 뛰어난 이유 중 하나는 샤딩(Sharding)이다. 샤딩이란, 데이터를 여러 개의 조각으로 나누어 분산 저장하여 관리하는 기술이며, 샤드(Shard)는 샤딩을 통해 나누어진 데이터 블록이다.

Elasticsearch는 인덱스를 샤딩하여 샤드를 관리하고, 각 노드는 복수의 샤드로 구성된다. 인덱스는 논리적 단위이며, 실제 도큐먼트의 인덱싱과 검색은 샤드에서 이루어진다. 즉, 분산된 샤드를 하나의 논리적 단위로 묶은 것이 인덱스이다.

> [!warning] 
> **인덱스 생성 이후에는 샤드의 개수를 변경할 수 없다.** 그러나, 원하는 샤드 개수로 새로운 인덱스를 만들고, 기존 인덱스의 데이터를 새로운 인덱스로 이동시키는 것은 가능하다.

인덱스의 샤드 개수를 변경할 수 없는 이유는, 아래 Elasticsearch의 “**샤드 라우팅**” 방식을 참고하자.

> [!info] 샤드(Shard) Routing
> 도큐먼트를 저장할 샤드를 결정하는 것을 라우팅이라고 한다. 도큐먼트는 기본적으로 모든 노드에 걸쳐 분산되어 저장되기 때문에 하나의 샤드에 많은 데이터가 집중되지 않는다. 이러한 라우팅은 기본적으로 자동으로 수행되며, 다음 공식을 사용하여 도큐먼트가 저장될 샤드를 결정한다.
> shard = hash(_routing) % primary 샤드 개수

#### Replica Shard
레플리카 샤드의 개수는 인덱스를 생성할 때 정의되며, 기본적으로 primary 샤드 1개마다 레플리카 샤드 1개가 생성된다.
![](https://i.imgur.com/lFPtgwK.png)
- 고가용성: 노드나 샤드에 장애가 발생했을 경우에 백업 역할을 수행하여 고가용성을 제공
	- 고가용성을 실현하기 위해 레플리카 샤드는 primary 샤드와 같은 노드에 할당되지 않음
- 검색 성능 향상: primary 샤드가 위치한 노드에 심한 부하로 인하여 응답이 느린 경우, 해당 primary 샤드의 레플리카 샤드가 위치한 다른 노드에 대신 요청하여 좀 더 빠른 검색을 수행할 수 있음

#### Primary Shard
primary 샤드는 여러 개의 레플리카 샤드로 복제될 수 있는데, 모든 레플리카 샤드와 primary 샤드는 동기화된 상태를 유지해야 한다. 레플리카 샤드 그룹이 primary 샤드와 동일한 상태를 유지하지 못할 경우, 쿼리 결과의 일관성이 떨어지게 된다.

예를 들어, 도큐먼트가 레플리카 샤드 A에서만 삭제가 되었다면, A에서 쿼리가 수행될 경우에는 도큐먼트를 읽어올 수 없으나 다른 레플리카 샤드에서 쿼리가 수행될 경우에는 도큐먼트를 읽어올 수 없게 된다.

Elasticsearch는 모든 샤드를 동기화하기 위하여 primary 샤드를 모든 인덱싱 작업의 진입점으로 사용한다. 즉 도큐먼트의 추가, 수정, 삭제 등 인덱스의 영향을 미치는 모든 요청은 가장 먼저 primary 샤드로 전달된다

### Segment
![](https://i.imgur.com/5hetwYG.png)

Elasticsearch의 샤드는 하나의 Lucene 인스턴스이며, 여러 개의 세그먼트를 포함하고 있다. **세그먼트는 Elasticsearch에서 인덱스가 물리적으로 저장되는 가장 작은 단위로, 세그먼트 내부에는 인덱싱된 데이터가 역색인 구조로 저장되어 있다. 기본적으로 인덱싱된 도큐먼트는 하나의 세그먼트로 저장된다.** Lucene 인덱스는 검색 요청이 들어오면 모든 세그먼트에 걸쳐 순차적으로 검색을 수행하고, 이를 통합해서 하나의 결과로 응답한다.

**세그먼트는 한 번 디스크에 저장되면 수정이 불가능한 불변 데이터(Immutable)이다.** **도큐먼트를 수정할 경우 도큐먼트가 포함된 세그먼트를 변경하지 않고, 수정 사항이 반영된 새로운 세그먼트를 생성한 다음 기존 세그먼트를 삭제하는 방식을 활용한다.** 도큐먼트를 삭제할 시에도 세그먼트 내의 도큐먼트를 실제로 삭제하지 않고, 삭제할 도큐먼트라고 표시(mark)만 해둔 다음 검색할 때는 해당 도큐먼트를 읽지 않도록 처리한다.

세그먼트에 대한 검색은 병렬적으로 수행할 수 없기 때문에 세그먼트의 수가 많을 수록 검색 속도가 느려진다. 그래서 Lucene은 검색 성능을 높이기 위해 정기적으로 백그라운드에서 세그먼트 파일을 물리적으로 하나의 큰 세그먼트 파일로 병합하고, 삭제 표시한 도큐먼트를 실제로 세그먼트에서 삭제한다. 이를 **세그먼트 병합**이라고 한다. 세그먼트 병합은 물리적인 저장 공간에서 이루어지기 때문에 많은 CPU와 I/O 리소스를 사용한다. 대량의 데이터 인덱싱을 수행할 때는 세그먼트 병합을 비활성화하는 것이 좋고, 적절한 세그먼트 병합 정책과 스케줄러 활용하여 서버 성능을 최적화할 수도 있겠다.

## Indexing Internal
![](https://i.imgur.com/t6XAfvz.png)

문서 색인 요청을 하면, 루씬은 곧바로 세그먼트를 생성하지 않는다. 왜냐면 세그먼트 생성이란 곧 디스크에 쓰는 것을 말하는데, 이 작업은 리소스가 많이 들기 때문이다. **문석 색인 요청이 들어오면 Lucene은 문서를 분석해서 역색인 (Inverted Index) 을 생성한다.**

### In-memory buffer
그 후 가장 먼저 하는 일은 In-memory buffer 에 쌓는 것이다. 메모리 기반이기 때문에 작업 속도는 빠르다. 문서 색인, 업데이트, 삭제 등의 작업이 수행되면 루씬은 이러한 변경들을 메모리에 들고있다가 주기적으로 디스크에 flush 한다.

하지만 아직 문서는 검색할 수 없다. 왜? 아직 세그먼트가 생성되지 않았으니까! 루씬은 색인한 정보를 파일로 저장하기 때문에 루씬에서 검색을 하려면 먼저 파일을 열어야한다. 루씬은 파일을 연 시점에 색인이 완료된 문서만 검색 할 수 있다. 이후 색인에 변경사항이 발생했고 그 내용을 검색 결과에 반영하고 싶다면 파일을 새로 열어야한다. 


> [!info] Inverted Index (역색인)
> 색인이 문서에서 키워드를 쉽게 찾을 수 있도록 정렬한 형식이라면, 역색인은 반대로 키워드를 이용해서 문서를 찾는 방식을 말한다. 
> 
> 예를들어 특정 키워드를 찾고 싶을 때 책 뒷쪽에 찾아보기를 이용해 정렬된 목록을 살펴본 이후에, 해당 키워드에 해당하는 페이지를 확인하여 키워드를 찾는 행위이다.
> ##### 색인을 사용한 검색
> ![](https://i.imgur.com/nRXoeoK.png)
> ##### 역색인을 사용한 검색
> ![](https://i.imgur.com/JEm3nQx.png)

### Lucene Flush
버퍼에 저장된 데이터를 Segment 파일 포맷으로 인코딩하여 `write()` 시스템 콜을 통해 페이지 캐시에 데이터를 쓴다. 루씬 플러시가 이루어지려면 다음 조건이 만족해야 된다:
- `Indexing Buffer` 가 Full 상태일 경우
- `refresh_interval` 을 통해 설정된 주기가 만료되었을 경우 (default : 1초)
- ES API(_refresh)의 명시적 호출이 발생할 경우

물리 디스크에 바로 쓰는 것보다 비교적 비용이 적게 들며 이때 페이지 캐시에 세그먼트가 업로드 되었으므로 검색이 가능한 상태가 된다. flush 까지만 해도 문서를 검색할 수 있지만 캐시이다 보니 데이터가 유실될 위험이 있다. 따라서 해당 세그먼트는 uncomited 상태이므로, 그 다음 단계인 Lucene Commit 이 필요하다.

### Lucene Commit
Page Cache에 저장된 Segment 파일을 실제 물리 디스크에 쓰는 과정이다. 정확히는, 루씬은 `fsync()` 시스템 콜을 통해 주기적으로 커널 시스템의 페이지 캐시의 내용과, 실제 디스크에 기록된 내용의 씽크를 맞추는 작업을 의미한다. 
본 스탭은 다음의 조건을 만족할 경우 Trigger 된다:
- `Page Cache`가 `Full` 상태이며 OS 알고리즘에 의해 선택된 경우
- `Elasticsearch`의 `Flush` 주기가 만료되었을 경우
- ES API(_flush)의 명시적 호출이 발생할 경우

Lucene Commit은 `Disk I/O`가 발생하므로 비용이 많이 드는 작업이지만 물리 디스크에 기록되므로 비로소 안전한 상태가되며, Segment는 Commited 상태가 된다.

Elasticsearch의 flush 작업은 내부적으로 Lucene Commit을 거치게 되며, **Lucene Flush 와 Elasticsearch Flush는 다른 개념이기 때문에 절대 혼동하면 안된다.**

| **ElasticSearch API** | **Lucene**         |
| --------------------- | ------------------ |
| /refresh              | lucene flush 작업 수행 |
| /flush                | lucene commit 수행   |

Elasticsearch flush 작업은 Elasticsearch refresh 보다도 훨씬 비용이 드는 작업이기 때문에 refresh와 마찬가지로 적절한 주기로 수행된다. 

### Translog
![](https://i.imgur.com/daSoVnR.png)

엘라스틱 서치에 색인된 문서들은 Lucene Commit 까지 완료되어야 디스크에 안전하게 기록된다. 그렇다고 문성 ㅔ변경사항이 있을 때마다 Lucene Commit을 수행하기에는 commit은 큰 비용이 드는 작업이다. 하지만 변경 사항을 모아서 commit 한다면 장애가 발생할 때 미처 commit 되지 않은 데이터가 유실될 유려가 있다. 이런 문제를 해결하기 위해 엘라스틱서치 샤드는 모든 작업마다 translog라는 이름의 작업 로그를 남긴다.

translog는 색인, 삭제 작업이 루신 인덱스에 수행된 직후에 기록된다. translog 기록까지 끝난 이후에야 작업 요청이 성공으로 승인된다. 엘라스틱 서치에 장애가 발생한 경우 엘라스틱 서치는 샤드 복구 단계에서 translog를 읽는다. translog 기록은 성공햇지만, 루씬 commit에 포함되지 못했던 작업 내용이 있다면 샤드 복구 단계에서 복구된다.

그런데 translog 가 너무 커지면 샤드 복구 시간이 오래 걸리게된다. 이를 방지하기 위해서는 translog의 크기를 적절히 유지해줄 필요가 있다. 앞에서 살펴봤던 Elasticsearch flush가 백그라운드에서 주기적으로 수행되며 translog의 크기를 적절한 수전으로 유지한다.

translog에는 디스크에 `fsync` 된 데이터만 보존된다. 클라이언트가 색인, 삭제, 업데이트 등의 요청을 보냈을 때 엘라스틱 서치는 translog에 성공적으로 `fsync` 됐을 때에만 성공을 보고한다.

### Merge
Lucene의 검색은 모든 세그먼트를 대상으로 수행된다. 불변인 세그먼트의 개수를 무적정 늘려갈 수는 없기 때문에 루씬은 중간중간 적당히 세그먼트의 병합을 수행한다.

세그먼트 병합은 비싼 작업이지만, 일단 병합을 하고나면 검색 성능의 향상을 기대할 수 있다. `forcemerge API` 를 통해 명시적으로 세그먼트 병합을 수행 할 수도 있다. 다만 명시적인 세그먼트 병합은 더 이상 추가 색인이 없을 것이 보장될 때 수행해야 좋다. 

## Strategies (performance tuning)
### Client Strategy
#### Bulk Indexing
ES는 문서 색인을 위한 대량 API를 제공합니다. 당연히 이것은 색인을 훨씬 빠르게 만들어줍니다. 데이터에 적합한 배치 크기를 결정하기 위해 일부 벤치마킹을 수행하는 것이 좋습니다.
#### Parallelism
ES는 본질적으로 수평으로 확장되므로 색인 작업도 그렇게 해야 합니다. 병렬로 실행될 수 있는 여러 워커에 데이터를 분산하는 것이 중요합니다. Elasticsearch 스레드 풀 대기열이 가득 차면 발생하는 TOO_MANY_REQUESTS (429)와 같은 오류에 주의하십시오 (그리고 그런 경우 지수 백오프를 사용하는지 확인하십시오).

#### Response Filtering
Elasticsearch가 반환하는 응답을 줄일 수 있는 filter_path 매개변수가 있습니다. 이 매개변수는 점 표기법으로 표현된 필터의 쉼표로 구분된 목록을 가져옵니다.

```
POST "es-endpoint/index-name/_bulk?filter_path=-took,-items.index._index,-items.index._type"
```

#### Aggregate Before saving
이것은 이미 집계된 정보가 있는 배치 작업을 실행하는 대신 "임의" 작업(예: 사용자가 사용자 이름을 업데이트하는 경우)을 통해 문서를 업데이트하는 경우 특히 중요합니다.

예를 들어 소셜 네트워크 프로젝트에서 Elasticsearch를 전체 텍스트 검색에 사용하고 사용자가 새 팔로워를 얻을 때마다 사용자 문서를 업데이트해야 하는 경우를 생각해보십시오. 곧 여러 시간 초과 문제와 전반적인 지연이 발생할 것입니다. 단순한 필드를 업데이트할 수 있지만 Elasticsearch는 현재 문서를 삭제하고 완전히 새로운 문서를 생성해야 합니다!

여기서 간단한 해결책은 Redis, Kafka 또는 다른 수단을 사용하여 이러한 사용자 변경 사항을 "버퍼링"하고 그 다수의 문서 편집을 Elasticsearch에 저장하기 전에 하나의 문서로 집계하는 것입니다. 게다가 "키"별로 그룹화하고 시간 창을 기준으로 한 다음 대량 작업을 사용하여 이러한 문서를 ES로 보내는 것이 좋습니다.


### Index Strategy
#### Refresh Interval
이것은 아마도 인덱스 수준의 구성 중에서 가장 큰 차이를 만들어낼 것입니다.

새로 고침 작업은 새 데이터를 검색 가능하게 만듭니다. 새로 고침이 발생하면 메모리에만 존재하는 최근에 인덱싱된 데이터가 새로운 Lucene 세그먼트로 전송됩니다. 이 작업은 이러한 세그먼트를 디스크에 플러시/커밋하지 않지만 데이터는 translog 덕분에 안전합니다. 나중에 이에 대해 더 자세히 알아보겠습니다.

Elasticsearch는 지난 30초 동안 색인에 대한 검색 요청이 하나 이상이면 매 초마다 새로 고침을 실행합니다.

Elasticsearch를 사용하고 있다면 시스템이 이미 최종 일관성에 준비되어 있으며 새로 고침 간격을 늘리는 것이 좋은 옵션일 수 있습니다.

배치 색인 작업 중에 인덱스의 새로 고침 간격을 더 크게 설정한 다음 작업이 완료된 후에 다시 기본값으로 설정할 수 있습니다. 다양한 동시 작업이 진행 중인 경우 어느 정도의 새로 고침 간격을 견딜 수 있는지 이해하는 것이 중요합니다.

#### Auto-Generated iDs
Elasticsearch가 대신 ID를 생성하도록 허용하면 Elasticsearch가 고유성을 확인할 필요가 없기 때문에 문서 생성 속도가 높아집니다.

자동 생성 ID를 사용하는 것의 성능 향상은 1.4 버전 이후에는 훨씬 더 명확해졌습니다. 그 이후로 Elasticsearch ID 조회 속도가 크게 향상되어 자체 ID를 사용할 때의 패널티가 줄어들었습니다.

그러나 "Lucene 친화적인" 형식을 사용하는 경우에만 해당됩니다. 좋은 ID에 대한 훌륭한 기사를 여기에서 찾을 수 있습니다.

예로는 0으로 패딩된 순차 ID, UUID-1 및 나노시간이 있습니다. 이러한 ID는 일관된 순차 패턴을 가지고 있어 압축률이 높습니다. 반면 UUID-4와 같은 ID는 본질적으로 무작위이므로 압축률이 낮고 Lucene의 성능이 느려집니다.

또한 "일반" 필드를 사용하여 "자체 ID"를 저장할 수도 있지만 ES가 해당 문서를 포함하는 샤드를 알고 있는 빠른 라우팅, 고유성 보장, ID에 따른 삭제 등과 같은 장점을 잃게 됩니다.

#### Disable Replicas
대량 색인 작업 중에 복제를 비활성화할 수 있다면 색인 속도도 크게 향상됩니다.

문서를 색인할 때 각 복제본에 의해 색인됩니다. 복제본의 수만큼 작업이 중복되어 수행됩니다.

반면에 대량 작업 전에 그들을 비활성화하고 대량 작업 후에만 활성화하면 새 정보가 분석되거나 병합되는 과정 없이 새 정보가 직렬화된 이진 형식으로 복제됩니다.


### Node Strategy
#### Indexing Buffer Size
이 설정은 Elasticsearch가 색인에 대한 메모리를 얼마나 예약할지를 제어합니다. 기본값은 힙의 10%입니다. 이것은 노드의 모든 색인에서 공유되므로 각 인덱스 당 최소 512MB가 할당되어 있는지 확인해야 합니다. 트랜스로그 크기를 늘리면 이러한 설정도 조정하여 이르게 플러시되지 않도록 해야 합니다.
#### Translog
트랜스로그는 Elasticsearch 트랜잭션 로그입니다. 각 샤드당 1개가 있으며 메모리 버퍼와 함께 업데이트되며 충돌 시 Lucene에 데이터를 영구적으로 저장하는 데 사용될 수 있습니다. 일정 크기(기본값은 512MB)에 도달하면 모든 메모리에 있는 Lucene 세그먼트가 디스크에 커밋되는 플러시 작업이 트리거됩니다. 이 플러시 작업은 Lucene 커밋 형태로 이루어집니다. 커밋 중에 메모리에 있는 모든 세그먼트가 단일 세그먼트로 병합되어 디스크에 저장됩니다.

상상할 수 있듯이, 이것은 고비용 작업입니다. 트랜스로그 크기를 늘려 디스크에 더 큰 세그먼트를 생성하고 이러한 비용이 큰 작업 주기를 줄일 수 있습니다.

이 값을 조절하는 필드는 flush_threshold_size입니다. 이에 대해 더 읽어보세요.

세그먼트 병합 스로틀링 (ES 6에서 사용 중지됨)

이 설정에 대한 많은 오해가 있는 것을 여러 기사에서 볼 수 있으므로 여기에 특별한 주의를 기울일 것입니다:

Elasticsearch 2부터 병합이 소프트웨어가 속도를 추적하여 그 현재 부하와 서버 성능에 따라 IO 제한을 변경하는 Lucene의 적응형 병합 IO 스로틀링을 사용합니다.

Elasticsearch 6부터는 indices.store.throttle.max_bytes_per_sec 및 indices.store.throttle.type과 같은 설정이 더 이상 존재하지 않습니다. 여기에서 확인할 수 있습니다.

#### Segment Merge Throttling (ES6 이후 비활성화)
이 설정을 사용하면 모든 읽기를 "팔로우" 인덱스로 직접 전달하고 쓰기는 "리더" 인덱스로만 전달할 수 있습니다. 이렇게 하면 읽기가 쓰기와 경쟁하지 않습니다.


### OS & Server Strategy
#### Disable Swap
스왑은 성능을 떨어뜨립니다. Elasticsearch는 많은 메모리를 사용하므로 조심하지 않으면 스왑이 시작될 수 있습니다.
#### File System Cache
리눅스는 자동으로 여유 메모리를 파일 캐시로 사용합니다. Elastic은 Elasticsearch를 실행하는 머신의 메모리의 절반 이상을 파일 시스템 캐시로 사용하는 것을 권장합니다.

ES_HEAP_SIZE를 기계 메모리의 50% 이상으로 설정하지 않도록 주의하십시오. 이렇게하면 나머지가 파일 시스템 캐시에 사용 가능합니다. 또한 32GB 이상의 HEAP을 가지고 있으면 성능이 저하되고 메모리가 두 배로 사용됩니다.

#### Storage Type
NFS 또는 EFS와 같은 네트워크 디스크를 피하고 항상 SSD (가능하면 NVMe)를 사용하십시오. AWS EBS와 같은 하드웨어는 좋은 옵션이 될 수 있지만 직접 연결된 디스크는 항상 더 빠르며 특히 RAID 설정을 사용하는 경우입니다.